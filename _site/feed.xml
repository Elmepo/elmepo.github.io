<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-AU"><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en-AU" /><updated>2025-12-23T22:48:23+11:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Scott Gardner</title><entry><title type="html">Why Oncall Rotations Break</title><link href="http://localhost:4000/blog/why-oncall-rotations-break" rel="alternate" type="text/html" title="Why Oncall Rotations Break" /><published>2025-12-21T00:00:00+11:00</published><updated>2025-12-21T00:00:00+11:00</updated><id>http://localhost:4000/blog/why-oncall-rotations-break</id><content type="html" xml:base="http://localhost:4000/blog/why-oncall-rotations-break"><![CDATA[<h1 id="blog-header">Why Oncall Rotations Break</h1>

<p>Oncall is on the few guarantees in life as a modern software engineer working on anything that’s expected to be constantly available. Whether you’re working on critical financial infrastructure, or a simple habit tracking app, most software engineers at high performing companies are expected to find some way to make sure that someone is always available in case things truly go south.</p>

<p>In all my years working on cloud infrastructure, I’ve seen a few different approaches to oncall. Some good, many bad, and most falling somewhere in between. Recently I was even responsible for running a schedule myself, and while it wasn’t perfect, it was good enough. So I wanted to take some time to write a little bit about specifically what went right and what went wrong with that oncall schedule.</p>

<p>We were a team of 4 engineers, so the best rotation was a standard 24/7 approach. Once a month, one engineer would become the oncall engineer, responsible for responding to any incidents and alerts, as well as performing any required maintenance work. Additionally, we also decided that the oncall engineer would be responsible for fielding any external requests. In this way, the other team members would be free to focus on their longer term projects while the oncall engineer took care of any pressing issues, questions, and concerns. We believed that this would present a clear point of contact for the rest of the company, an easy way to know who to talk to when issues appeared.</p>

<p>This was important because informal availability scales until it doesn’t. When an entire team is away on a public holiday, you find yourself having to very quickly determine relative risk levels of allowing issues to grow for another day or longer, while trying to find the one engineer that’s willing to leave their families for potentially hours while resolving the issue before it spirals out of control.</p>

<h2 id="so-what-went-right-and-what-went-wrong">So, what went right, and what went wrong?</h2>

<p>Thankfully, a lot went right - the overall workload was often manageable, and on the rare occasion when it became too much, the team was aware of how to escalate issues and how to get the help they needed (whether that was developers to help debug a memory leak or merely an extra pair of hands to handle the alerts). The rotation was fair, and consecutive weeks oncall was incredibly rare, only happening when engineers were shifting around schedules to fit in holidays or important life events.</p>

<h3 id="things-break-when-incentives-disagree">Things break when incentives disagree</h3>

<p>One of the earliest things that went wrong was the process for external teams getting attention from the oncall engineer. This was something that was persistently a thorn in our side, and one that we could have done better to set ourselves up for success. Initially devops engineers worked as part of vertical scrum teams, which led to competing incentives between oncall and vertical work. Worse still, this could sometimes lead to conflict between entirely different teams as they began to believe that each other were unfairly using what they saw as “their” resource. We resolved this  by removing the devops engineers from the verticals entirely, becoming its own separate platform team, serving all aspects of the business equally. This also had the added benefit of meaning that we were able to spend more time on requests that didn’t come in through verticals (such as from non-development teams).</p>

<h3 id="process-will-lose-to-convenience-if-youre-not-careful">Process will lose to convenience if you’re not careful</h3>

<p>The official way to request assistance from the oncall devops engineer was to create a ticket, but  developers would often reach out directly  to team members they had personal relationships with first to get work done, and those engineers would often try to fit the request into their own schedule. Inevitably, this became the fastest way to resolve some issues, because these people were, after all, friends. And once a developer knew they could use this backdoor, they would continue to do so. After all, they had their own objectives and were merely trying to close them out as quickly as they could. Why should they care if it caused friction in another team?</p>

<p>Resolving this requires understanding what specifically was leading to people to use the shortcut over the official process. In the end, we determined that it was a mixture of not always knowing who specifically was oncall, having trouble seeing the progress of the queue, and often being unaware of the process because they so rarely used it. By targeting the root cause of each issue, we were able to put a stop to the behaviour.</p>

<h3 id="scope-and-expectations-need-to-be-as-crystal-clear">Scope and expectations need to be as crystal clear</h3>

<p>Another stepping stone was clarity of scope and expectations. What specifically should you respond to and what don’t you? It seems easy enough but you very quickly learn the nuances to what people consider important issues. We all know a database going offline is bad. But what about rising CPU usage or a full disk? What about when the preproduction environment becomes fully unusable on a public holiday that only affects your team, but not the developers in a different country, who are now blocked from most forms of their work?</p>

<p>Personally, I found that these issues were resolved best on a case by case basis, while also building up a strong historical precedent that the team can rely upon to determine what is and isn’t something to worry about. It’s important that these are documented and communicated, however, so that teams everywhere can also understand what they can expect in terms of coverage and reliability.</p>

<h3 id="oncall-burnout-is-caused-by-more-than-just-volume">Oncall burnout is caused by more than just volume</h3>

<p>Oncall can very quickly increase stress and burnout, but it’s important to remember that the sources of burnout aren’t just the sheer volume of alerts. It also comes from things like not knowing if an alert is important or not. This is critical to manage because as engineers receive more and more alerts, a mental map is formed of what needs to be investigated and what can be ignored. This becomes very dangerous if something that was previously not an important alarm (such as CPU usage in a datacentre that’s still being deployed) becomes an actually important alarm (like when that datacentre starts receiving production traffic).</p>

<p>It’s crucial that alerts are more often than not “important messages” rather than a stream of notifications. Finding this line is complex and worthy of an entire book in itself, but in my experience it’s relatively easy to identify the alerts you know aren’t important enough in unto themselves to justify waking up someone for. That gets you enough of the way towards avoiding painful issues with burnout and stress. You’ll probably never reach a peak ideal of alert quality and frequency, but merely trending in the right direction is usually good enough.</p>

<p>No oncall rotation is perfect and there will always be issues to resolve with the process. Each oncall system is unique to the team and environment that it exists in. Maybe you only need coverage from 9-5 because there’s no after hours traffic, or maybe you need somebody actively watching a dashboard due to high SLA expectations. But from my experience there does exist a common set of problems that are guaranteed to cause issues if not prepared for, that aren’t immediately obvious when first setting out, but that can be discovered with careful forethought and planning. Understanding your constraints and needs, and what works well in those limitations, is key to having a positive oncall experience rather than a negative one.</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[Why Oncall Rotations Break]]></summary></entry><entry><title type="html">On the joy of making bad things</title><link href="http://localhost:4000/blog/the-joy-of-making-bad-things" rel="alternate" type="text/html" title="On the joy of making bad things" /><published>2025-05-30T00:00:00+10:00</published><updated>2025-05-30T00:00:00+10:00</updated><id>http://localhost:4000/blog/the-joy-of-making-bad-things</id><content type="html" xml:base="http://localhost:4000/blog/the-joy-of-making-bad-things"><![CDATA[<h1 id="on-the-joy-of-making-bad-things">On the joy of making bad things</h1>
<p>Over the years, one of the simple joys in life I’ve found is to make bad things. To make things that are undeniably terrible and that no one particularly wants to use. For me, it’s all about the act of making something - I’ve always found more love in the act of making something than in the end result. Really this is why I like making bad things rather than good things. For one thing, it’s so much easier to make a bad thing. Making good things requires a lot of effort and time - finding solutions to unique problems or making difficult decisions. Making bad things on the other hand, merely requires one thing - the desire to make something.</p>

<p>Maybe it’ll turn out good - after all many good things started off originally as a bad thing, in fact basically everything has to start off first as a bad thing. But there’s no requirement to continue with bad things. Get to where you want to get to, to where you’ve gotten what you want out of it, and then move on.</p>

<p>Often with me this winds up in writing implementations of programs that already exist. Like everybody else I’ve written a todo list application and a calculator. But I’ve also written a really inefficient rendering engine, a really bad LSP that wouldn’t work for even the most simplistic of languages, a program to backtest stock trading algorithms that somehow managed to be the slowest thing in this entire list, and I’m currently in the process of writing a vim like text editor, which spun out of absent mindedly wondering “How exactly <em>do</em> vim and other programs wipe the terminal but keep everything the same?”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p>

<p>Every time that I’ve made something bad however, I’ve learned something new or sharpened my skills. You might not think they’re connected, but the way that a graphics engine renders things is actually quite relevant to writing your own text editor. Sure you might not need to perform any 3d matrix multiplication to display a few lines of text, but approaches like dirty area rendering occlusion culling were incredibly important and I’d have probably never even considered them if I hadn’t previously implemented them when needing to improve the efficiency of my renderer to avoid melting my laptop CPU for anything more complicated than a couple of cubes.</p>

<p>The entire performance focused approach that you find in graphics rendering has been an incredible lesson when rewriting basic programs. I’ve come to appreciate just how many basic functions are abstracted out even when writing your own implementations. You might not think writing text to the screen is a performance heavy operation, but when you’re writing the TTY commands to actually do so, you very quickly gain an appreciation for just how often you’re jumping around and how easy it is for performance to degrade very quickly. There’s also an element of solutions that seem simple at first but become complex when you start to try to solve them.</p>

<p>Take for example, cursor movement across lines. Take for example the following example</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre>Line 1
Line 2
Another longer line
                 ^
A short line
A final line at the end
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The cursor position is represented by the <code class="language-plaintext highlighter-rouge">^</code>. If the user presses the up arrow key, where do we move the cursor? If we’re storing the cursor as x,y coordinates, then x,y-1 doesn’t exist. If we’re storing the cursor as the index in the line (here 32), there’s no way of knowing how many digits back inside the string we should move without knowing a lot of additional information that wouldn’t be smart to store/update with every cursor change, like the length of each line above it. And what about line 5? It’s just a <code class="language-plaintext highlighter-rouge">\r\n</code>, but there’s no “visual” character, so when the user presses the down arrow key, is this line being correctly represented in memory, or will we accidentally move the cursor too far, to line 6 (or worse still, the <em>end</em> of line 6)?</p>

<p>An interesting lesson for me was that there simply <em>was</em> no “good” solution. Or at least maybe there is, but I’m just not smart enough to solve it. After spending way too long thinking about it and coming up with a million different solutions, it turns out that realistically the two most common solutions are the more straight forward - either maintain two maps which convert from an index to x,y coords and vice versa, or maintain information about each line including the start and ending indexes within the string.</p>

<p>It’s the things like this that keep me sane - a reminder that despite it all sometimes the best solutions are also the worst solutions. That even the people who I greatly look up to because they’ve written useful, important, or even foundational programs still sometimes write functions that are messy or complex or straightforward with large O notation scales. Particularly as software engineers, it can be easy to assume that the best solutions are the ones that run in O(n) or O(logn), and that these solutions <em>must</em> exist and we just need to think hard enough about them. P vs NP aside, for the majority of us - and especially when working on problems that you <em>know</em> other people have solved before - it’s easy to assume that there truly is an easier solution.</p>

<p>This is often the hardest part of programming, and a large part of why I like making bad things rather than good things. A graphics renderer that can barely load any object with more than 100 vertices without crashing is hardly a useful program. It certainly won’t be used by anyone except myself when I randomly remember it about once a year. It lacks basic functionality even for the small files it can handle, only rotating on a specified set of axis and offering little to no colour options, let alone lighting. It’s still a graphics engine.</p>

<p>If I wanted to make it a good graphics engine, then I’d have to start making these hard decisions - when to sacrifice code readability and maintainability for performance, when to write an amazing implementation and when to just get something out. What options to offer to end users and what to keep hidden, and most importantly how to avoid edge cases on machines that I don’t control frying an end users machine because they were curious about something they saw pop up on github one day.</p>

<p>Which is another reason why I like bad things - nobody will ever care if the bad thing breaks. There’s a kind of grace and acceptance given to bad things that we would never accept giving to things that try to be good. If the program generating backtesting results for a trading strategy takes 15 minutes to finish, and only spits out a single image with obvious errors has some possible redrawing<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, it’s not exactly unexpected now is it? Nobody sane is putting any real money on the basis of it’s output and there’s no expectation of anything better. It’s slow and it’s janky, but if you’re curious if “buying the first stock to hit a 52 week high this week, every week” is objectively bad or good, well then it does what you need. If features start being added, performance improvements start being made, and bugs started getting fixed… Well then maybe some people might just start to assume some things that they shouldn’t about the validity of the results.</p>

<p>I’ve tried to always take this mindset into everything I do. I feel like it’s more about getting something out there, getting something that somebody, even if it’s only ever you, can interact with. Because sometimes the most value you gain is in just doing the thing, even if what you get at the end is a bad product. It’s generally pretty rare to be unable to go back and fix your mistakes or improve upon what you’ve already got, it’s basically the only reason any startup is ever able to get anywhere.</p>

<p>In short:</p>
<h2 id="save-the-good-for-later---make-the-bad-thing-now">Save the good for later - make the bad thing now.</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>For those curious, it’s done via an <a href="https://www.gnu.org/software/screen/manual/html_node/Control-Sequences.html#:~:text=%3F1047%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Alternate%20Screen%20(new%20xterm%20code)%0A%20%20%20%20%20%20%20%20%20%20%20%3F1049%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Alternate%20Screen%20(new%20xterm%20code)">ANSI escape command</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Redrawing is when the historical results change based on new information. It means that an indicator’s historical information cannot be trusted. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[On the joy of making bad things Over the years, one of the simple joys in life I’ve found is to make bad things. To make things that are undeniably terrible and that no one particularly wants to use. For me, it’s all about the act of making something - I’ve always found more love in the act of making something than in the end result. Really this is why I like making bad things rather than good things. For one thing, it’s so much easier to make a bad thing. Making good things requires a lot of effort and time - finding solutions to unique problems or making difficult decisions. Making bad things on the other hand, merely requires one thing - the desire to make something.]]></summary></entry><entry><title type="html">So when is scrum good?</title><link href="http://localhost:4000/blog/when-is-scrum-good" rel="alternate" type="text/html" title="So when is scrum good?" /><published>2025-05-28T00:00:00+10:00</published><updated>2025-05-28T00:00:00+10:00</updated><id>http://localhost:4000/blog/when-is-scrum-good</id><content type="html" xml:base="http://localhost:4000/blog/when-is-scrum-good"><![CDATA[<h1 id="so-when-is-scrum-good">So when is scrum good?</h1>

<p>Never let it be said that I’m ideological. <a href="/blog/you-dont-need-scrum">Look, I don’t like Scrum</a> - I think it’s largely an artefact of a time from before I was even born. But I also think it was a required step in the journey from where software started off, with rigidly defined steps and roles, to a brighter future. It’s certainly not the worst possible way to organise software delivery teams and has it’s benefits. We have to understand these benefits, because otherwise we risk recreating scrum in the aggregate, with none of the benefits and all of it’s flaws because we collectively fail to grasp why scrum works and why it fails.</p>

<h2 id="1-scrum-lifts-up-bad-developers">1. Scrum lifts up bad developers.</h2>
<p>If you work in the software industry long enough, you’ll eventually meet some truly bad developers. Sometimes they’re simply junior developers. People still learning the ropes and with either no prior context or who’ve never been taught how to do things and why. Other times, they’re people who make you wonder how they snuck past the interview process and how they’re allowed to stay.</p>

<p>Developers who spend months working on a feature without even checking to see if it fixes the problem they’re trying to solve. Developers who continually run into the same issues, or who refuse to take any ownership of their code once it’s been committed. Hell I once worked with someone who wrote tests for their code, but then updated the deployment logic to just ignore any test failures.</p>

<p>Scrums approach, focusing on short to medium length feedback loops consisting of: Deciding what you want to achieve over the next x days, Trying to do that, Thinking about what went wrong and what went right - <strong>will</strong> take any particularly bad developer and forcefully pull them up to a relatively low baseline standard.</p>

<h2 id="2-scrum-protects-development-teams-from-stakeholders">2. Scrum protects development teams from stakeholders</h2>
<p>Along the same lines, scrum protects development teams from undue outside influence. It makes it more difficult for product or sales people to try and force a team to drop what they’re doing and focus on their request. It makes those same people an active participant in the development process, asking them to review the work that’s going on and avoid painful mistakes where a team spends months on a feature only to discover at the last minute it’s the complete opposite of what was requested.</p>

<p>In the best case scenarios, teams are able to use the sprint based nature of scrum to spend time proactively paying technical debt and incorporate more robust technical requirements into their development cycle to avoid increasing their technical debt, something that is difficult (particularly in more toxic companies) when not using sprints. Scrum’s rigid processes act as a kind of bulwhark against these kinds of issues, even if it still doesn’t completely stop them. In low performing teams and toxic companies, being able to provide any kind of support for good development practices is too good of an opportunity to pass up.</p>

<h2 id="3-scrum-usually-forces-developers-to-avoid-silos">3. Scrum (usually) forces developers to avoid silos</h2>
<p>Whilst not <em>strictly</em> scrum, I think it’s fair to say that 99 percent of scrum teams consist of multiple developers across different functions. This is without a doubt a massive benefit. By forcing developers from different functions to consistently interact with people from other functions, you avoid a whole host of problems. Your backend developer is aware of how the frontend will consume their api. QA is aware of how exactly the backend is processing data, so they can ensure all bases are covered by their tests.</p>

<p>In a perfect world, this will also result in a cross pollination effect, where each developer can start to pick up skills and approaches from other functions. You might not end up with a team of fullstack engineers proficient in every language and framework under the sun, but at least they’ll start to have an appreciation for the limitations and strengths of the tools used by everyone in the team.</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[So when is scrum good?]]></summary></entry><entry><title type="html">What’s left to do</title><link href="http://localhost:4000/blog/todo" rel="alternate" type="text/html" title="What’s left to do" /><published>2025-05-27T00:00:00+10:00</published><updated>2025-05-27T00:00:00+10:00</updated><id>http://localhost:4000/blog/todo</id><content type="html" xml:base="http://localhost:4000/blog/todo"><![CDATA[<h1 id="todo">Todo</h1>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Add a picture to the about page</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Take pictures for the projects page
    <ul class="task-list">
      <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Text Editor</li>
      <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Blog</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Get text editor to v1</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Deploy Cafeok project to the public</li>
</ul>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[Todo]]></summary></entry><entry><title type="html">You don’t need scrum</title><link href="http://localhost:4000/blog/you-dont-need-scrum" rel="alternate" type="text/html" title="You don’t need scrum" /><published>2025-05-26T00:00:00+10:00</published><updated>2025-05-26T00:00:00+10:00</updated><id>http://localhost:4000/blog/you-dont-need-scrum</id><content type="html" xml:base="http://localhost:4000/blog/you-dont-need-scrum"><![CDATA[<h1 id="blog-header">You don’t need scrum</h1>

<p>Something I’ve never really been able to mesh with a lot of people in my industry is that I just don’t get Scrum. It’s existence stands out as a weird anomaly in a field full of anomalies. As a part of our industry, in my opinion it’s the only standard that exists because we collectively have decided that against all evidence otherwise, it works.</p>

<p>Scrum is one of those strange things where you can find plenty of people talking about how nice it is. Lots of conferences about it and youtube videos waxing eloquent not just about it, but about hyper specific implementations and nuances <em>about</em> it. Strangely enough, however, no one’s ever bothered to ask if it actually works. It feels as though everyone just woke up one day and decided that this was it. People are quick to attach things to Scrum, but never really seem to be able to prove it’s benefits on it’s own merits. Much like the “Spotify Model”, something that Spotify used for about just long enough to create a god awful video talking about how great it was, before dropping it like a pile of hot rocks.</p>

<p>If you read anything about scrum, scrum proponents are almost constantly, whether on purpose of not, using complex linguistic tricks to pretend that anything good that has ever happened in software was because of scrum.</p>

<p>Agile is good, and Scrum says it’s agile, ergo scrum is good. Lots of high performance teams use standups, and scrum uses standups, ergo high performance teams use scrum. On and on and on, it seems like despite very few high performance teams seeming to even acknowledge scrum exists - let alone going to scrum conferences or talking about scrum or singing it’s praises to anyone who’ll listen.</p>

<p>So then why does basically everyone use scrum? I mean, besides inept technical leadership, because really scrum can’t be blamed for that. That’s unfortunately a much bigger and much more common problem. I’ve always been perplexed at how scrum can so constantly be a part of discussions around “high performing teams” when the actually high performing teams at places like Google, Facebook, and Netflix, don’t use scrum at all.</p>

<p>That’s not to say that I don’t believe there’s a few things that Scrum does have going for it. The great benefit of scrum I think, is that it is the great equaliser. Executed correctly, it can take any team of developers and make them all slightly worse than average. Maybe even average if you’re lucky. Forcing developers to actually think about the work they’re doing, making them think about what their next week or two is going to look like and how they can actually achieve something in that time, and then looking back on what they’ve done, can be pretty powerful.</p>

<h3 id="if-youre-working-with-low-performers"><strong>If you’re working with low performers</strong></h3>

<p>I mean, basically. Scrum’s whole deal is really great for taking people who are bad at their jobs - juniors or otherwise really poor engineers - and turning them into people who could meet basic bare minimums. It seems like whenever I see scrum success stories (where that success could actually be attributed to scrum), the common thread seems to be that the teams just weren’t that good in the first place. Which, sure, scrum will help with that. But honestly is that what you want? A team of people who have to be forced via strict processes to take a very basic level of ownership and responsibility over their work?</p>

<p>And what’s the cost of all of this? <strong>It’s that any developer that’s more than “just okay”, will also inevitably fall to that level.</strong> The key to good development work is fundamentally uninterrupted time to focus on the problem at hand. As Paul Graham once wrote: <a href="https://paulgraham.com/makersschedule.html">“[Programmers] generally prefer to use time in units of half a day at least”</a>. Scrum of course, instead takes the approach that if a developer is having difficulty solving a problem, then surely the problem is that they haven’t had <em>enough</em> meetings. The problem just isn’t defined well enough, so maybe a refinement session will help. Then after that refinement session maybe they could have a three amigos meeting to really clarify the problem. Of course they’ll still have the daily standup to go to, along with a review session.</p>

<p>It never ceases to amaze me that whenever I see scrum proponents talking about these very specific concerns from developers, they seem to be completely unable to conceptualise that their very solution is the problem. For any good developer, basically the only justifiable meeting is the daily standup and that’s about it. Virtually every other meeting is something that at best is net neutral and in most cases something that actively hurts what they’re trying to achieve.</p>

<h3 id="your-stakeholders-can-be-low-performers-too">Your stakeholders can be low performers too</h3>

<p>The one other thing that scrum has going for it is that the scheduled nature works really well with non technical stakeholders. When people can’t understand exactly why estimating technical tasks can be so inaccurate, forcing them into the same schedule the developers are using can have some really strong benefits. It doesn’t necessarily make the relationship perfect - everyone has worked on a project where the stakeholders changed everything mid sprint and then complained when goals weren’t met - but it does <em>improve</em> it.</p>

<p>There is, unfortunately a double edged sword in this faustian bargain. Inevitably when work is expressed in strict units of time, people begin to play politics with it. Technical debt almost always takes a backseat to feature work, often placed into the catchall bucket called “if we have time this sprint”. It’s also hard to argue with stakeholders why they should wait at least another two weeks for the feature they think will increase revenue by 10% while the team works on some complex technical issue that they can’t explain and has no direct monetary benefits. I think it’s no surprise that the single most common approach recommended to paying down any technical debt is to simply lie about how long something will actually take and then use that buffer to patch the holes.</p>

<p>This isn’t to say that without scrum stakeholders become technologists, approving any and all technical debt work developers request. But I think that there’s something to be said about the nature of longer timelines causing a lower tolerance to delays, particularly how it relates to viewing timing as a budget that should be spent. In my experience, leaving technical debt to “if we have time” results in solutions that are much worse and representative of the time available for the solution. If a team closes out all of it’s work a day earlier, yes, they <em>(may)</em> have a day now to work on technical debt. But rather than create a solution that solves the problem long term, developers are incentivised to instead create a solution <em>within that day</em>. In almost all cases, this merely kicks the can down the road, creating more technical debt that developers simply hope they’ll be able to justify spending a proper amount of time on in six months time.</p>

<h3 id="so-whats-the-solution-then">So what’s the solution then?</h3>

<p>In short - Hire better engineers.</p>

<p>Look it’s 2025. It’s not the 90s anymore when something like scrum was revolutionary. The idea of a developer saying they “just write code” and don’t need to think about what that code is actually doing for stakeholders, whether that’s generating new revenue or saving costs, is becoming exceedingly rare. Developers are taking more responsibility for what we write and most people will need to have an appreciation for the context even if they don’t think they have to. A developer is no longer just a developer but someone who has at least surface level knowledge of topics like QA and infrastructure. They don’t need to be reminded every two weeks that they’re updating a function because it’s not performant and smashing the database. Hell chances are that they’re the ones who pushed to change the function because they’re tired of being woken up at 3am when a random spike in traffic causes the database to keel over one too many times.</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[You don’t need scrum]]></summary></entry><entry><title type="html">You’re probably thinking about automation the wrong way</title><link href="http://localhost:4000/blog/thinking-about-automation-wrong" rel="alternate" type="text/html" title="You’re probably thinking about automation the wrong way" /><published>2025-05-23T00:00:00+10:00</published><updated>2025-05-23T00:00:00+10:00</updated><id>http://localhost:4000/blog/thinking-about-automation-wrong</id><content type="html" xml:base="http://localhost:4000/blog/thinking-about-automation-wrong"><![CDATA[<h1 id="youre-probably-thinking-about-automation-the-wrong-way">You’re probably thinking about automation the wrong way</h1>
<!-- {: #blog-header} -->

<p>In infrastructure there’s a term that gets thrown around a lot among SREs and Platform Engineers, “Sysadmin who codes”. As DevOps began gaining more popularity and roles began to change, with roles like Site Reliability Engineer, Platform Engineer, and DevOps Engineer<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, People who had previously worked as Systems Administrators, rarely if ever writing any code, were suddenly required to become programmers. Often used in a somewhat derogatory way, it’s presence is a strong indicator of how the DevOps community views ourselves and our roles - where we are and where we’ve come from.</p>

<p>The difference between an SRE and a “Sysadmin who codes” might not immediately be obvious, particularly to anyone not in our industry. After all, isn’t that what Site Reliability Engineering is all about? Isn’t that just what Google did? Hired Sysadmins who could code? Why would that be a bad thing? It’s easy to see how the narrative was formed, but the reality is that Google never did that. Instead, Google did the opposite. They hired Software Engineers and set them to working on their infrastructure. This (to some subtle) difference is responsible for arguably the biggest scism in our industry.</p>

<p>So what’s the difference? In short, it’s the approach and mindset, and to a smaller extent the skills and capabilities. “Sysadmins who code” often have a more process orientated mindset and a view to resolving problems using less abstract ways. Typically while they have the ability to write code, they lack any training and may find themselves unable to understand relatively basic algorithms and why they’re used. In my experience, the code I’ve seen from these kinds of engineers is functional, but not particularly maintainable.</p>

<p>The biggest way I’ve noticed this manifesting is the way in which people approach resolving problems via “automation”. To me it’s one of the biggest indicators of someone’s mindset and potential red flags to look out for when interviewing or talking to people. A “Sysadmin who codes” views a script as an automated replacement for themselves - a digital record of the actions they would take with little to no internal logic or problem solving. Most engineers I know, understand that the actions a person needs to take to perform a task isn’t always the actions that a computer should take.</p>

<p>Often, this also relates to how the program is run and where responsibility for any impacts lies. Most sysadmins I’ve seen take a certain view that programs shouldn’t make “serious” decisions, instead requiring user input or confirmation for those steps. On some level, this can be unavoidable - sometimes things are just too dangerous to avoid at least a confirmation. In my experience though, this is usually a sign that a process is broken somewhere, and that’s what should be focused on instead. In my opinion, good engineers understand that responsibility for a programs lie with the program itself, not on the user or process running the program. If I give you a program to reset the data in a test database, if it accidentally overwrites the production database, we shouldn’t blame the user but rather the system that allowed the mistake in the first place.</p>

<p>This will usually also be seen in a reverence for runbooks and documentation. Not that I have any issues with either - they’re incredibly important components of any system, but not everything needs to be documented and realistically everytime a runbook is written, you should be asking youself if that’s the best solution. This is where the sysadmins who code often have the biggest trouble in my experience. Historically that was the best way to solve problems as a sysadmin - write down exactly what you did to resolve an issue - after all maybe it’ll happen again next year long after you’re gone and no one else knows exactly what you did or even why. With computers though? They never forget and they never make mistakes or change how they do things, even when you want them to. In my view, self-healing script triggered by an alert &gt; Runbook explaining which script or pipeline to run &gt; Runbook explaining what commands to run.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

<p>All of this isn’t to say that there’s no space left for Systems Administrators in our industry, or even that a team solely of “Sysadmins who code” is a red flag in of itself. With these kinds of things I think it’s always important to remember the context that people are in - how big is the company and how complex is their infrastructure? How important is software to the business’s profit margins? You don’t need to be writing complex programs for a local accountancy. It is, however, important to watch out for when you <strong>do</strong> need to be tackling these complex problems.</p>

<p>If you’re working in an environment that requires self healing infrastructure, that requires <a href="uptime.is/three-nines">3 or more 9’s of uptime</a>, it’s more or less impossible to get there with people who have this kind of mindset. Complex, highly available environments require automated processes that are capable for thinking and reasoning for themselves<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. After all, if you have an SLA with no longer than 30 minutes downtime per month, you’re probably losing half of that time just in your oncall engineer responding to the alert. Add on that you’re almost certainly not alerting issues immediately but on some kind of timeseries based metric, and it’s not unimaginable that by the time the problem has occurred, alerted (and woken up) your oncall engineer, they’ve drearily booted up their laptop, looked at the issue and determined the script to run to fix the issue, you’ve already blown past not just this months SLA, but possibly next months as well. You need something that is a) never asleep and b) capable of immediately taking action.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Generally speaking I hate the term “DevOps Engineer” and consider it to be the same as “Scrum Master” - examples of roles that should never have existed and go against their very origins, but that’s a topic for another day. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>It’s always worth remembering that while it’s unlikely your cloud CI server will be down, it can happen and so the best self-healing system is either self-healing itself or simply calls a script that your oncall engineer <em>could</em> run themselves if the CI server did die. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Within reason <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[You’re probably thinking about automation the wrong way]]></summary></entry><entry><title type="html">Becoming a manager</title><link href="http://localhost:4000/blog/becoming_a_manager" rel="alternate" type="text/html" title="Becoming a manager" /><published>2025-05-22T00:00:00+10:00</published><updated>2025-05-22T00:00:00+10:00</updated><id>http://localhost:4000/blog/becoming_a_manager</id><content type="html" xml:base="http://localhost:4000/blog/becoming_a_manager"><![CDATA[<h1 id="thoughts-after-1-year-of-management">Thoughts after 1 year of management</h1>

<p>I’ve officially been a team lead, managing up to 4 people, for one year. Like many people, I had held unofficial leadership positions before, but the last 12 months marked the first time that was official, with all the ups and downs that come with it. It’s been an interesting journey - and I’ve learned some incredibly important, interesting, and often conflicting things about management.</p>

<p>The first thing that I had to come to terms with was just how different the job was. I was promoted internally to lead the very same team I had previously been part of, and so I assumed that there wouldn’t be that much difference. Sure I’d be in a few more meetings, I’d have to write the occasional report and deal with the odd interpersonal problem, but it’s not like much would change, right?</p>

<p>I couldn’t have been more wrong. For one thing, it wasn’t just “a few more meetings”. My calendar might have been free, but barely a day went by that I didn’t have multiple long conversations about some issue that needed to be raised or resolved, from both inside and outside my team. Along with necessary admin work and other duties, as a programmer I really started to understand PG’s Manager Time/Maker Time essay. My technical work quality was immediately directly tied to how much time I had that day.</p>

<p>This started to become a problem because as a Team Lead, I was still expected to perform technical tasks. I quickly found myself struggling to keep up with technical details and specifics, and would often find myself having to backtrack on something I said or committed to. I would eventually read that Google considers the Team Lead position to be one of the most stressful and complex positions for this exact reason - you need to be capable of performing both management and technical tasks just as good as somebody specialising in either, with half the time.</p>

<p>I was also surprised to learn just how much of the job was political. As a manager you’re more privy to the goings on in the company, and you find yourself thinking on a different level than you may have ever done as an individual contributor. You see the reasons why an underperforming team is still being kept around or why certain product lines are being explored, and you also start to understand exactly where you and your team sit in the value stream and (hopefully) the value they bring to your company.</p>

<p>This becomes a background process constantly running in your head. Suddenly, decisions aren’t necessarily so clear. You’re weighing up not just what the team wants to do and what they think is important, but how that will affect the team and the rest of the organisation. Spending time rewriting a service in a new language might help your team in the future, but another team relies on it and needs changes made yesterday or they might miss quarterly goals.</p>

<p>The words you use also suddenly become much more important. You’re hiring for a position and people are suggesting reaching out to a former colleague you know won’t be rehired. Do you avoid the topic or say something non-committal? People are complaining about how infrequently someone is in the office, do you reveal they’re going through an intense personal issue right now, or do you say nothing and potentially impact that person’s workplace relationships? When you’re talking to non-technical people, how do you communicate complex technical topics and problems and how they relate to the changing dates you’ve committed to?</p>

<p>There’s rarely any right answers in the role and you’re usually trying to find the right balance between multiple less than ideal scenarios. These issues are also very rarely visible on any kind of fair timeframe. You won’t know if you made the right decision until weeks, months, or potentially even years later. Coming from a programming background where getting fast feedback loops was considered baseline requirements, and changes that took longer than a few minutes to verify considered “slow”, this was easily the hardest aspect of management for me to come to terms with.</p>

<p>Gradually, however, you get better at it. In the same way a junior engineer doesn’t understand basic sorting functions at first and slowly over time learns the logic and reasoning behind them, you start to understand what you need to do, and decisions come to you more naturally. Sometimes, this is because you’ve been bitten before or you’ve been warned it could come up. Other times you just get a feeling in your stomach telling you which direction to take or what words to use even if you don’t really know <em>why</em> you think so. Eventually, things that were incredibly alien at first become more natural and effortless.</p>]]></content><author><name></name></author><category term="blog" /><category term="management" /><summary type="html"><![CDATA[Thoughts after 1 year of management]]></summary></entry></feed>